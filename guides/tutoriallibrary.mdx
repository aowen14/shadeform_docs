---
title: 'Tutorial Library'
icon: 'book'
iconType: 'solid'
---
### API Guides
<Card title="Run Docker Container" icon="docker" href="/guides/dockercontainers">
  Deploy a VM that automatically runs a Docker container
</Card>
<Card title="Run Startup Script" icon="scroll" href="/guides/startupscript">
  Deploy a VM that automatically runs a startup script
</Card>
<Card title="Deploy the most affordable GPU" icon="dollar-sign" href="/guides/mostaffordablegpus">
  Use Shadeform to find and deploy the most affordable GPU
</Card>
<Card title="Run vLLM" icon="microchip" href="/guides/vllm">
  Serve an LLM model using vLLM
</Card>
<Card title="Run TGI" icon="microchip" href="/guides/tgi">
  Serve an LLM model using Text Generation Inference
</Card>
<Card title="Setup Firewalls using UFW" icon="block-brick-fire" href="/guides/firewall">
  Provision network rules on your instance
</Card>

### Use Case Specific Guides
<Card title="Deploying GPU Containers" icon="docker" href="/guides/deployinggpucontainers">
  Deploy a GPU container on a VM instance via Shadeform's APIs.
</Card>
<Card title="Finding the Most Affordable GPUs" icon="dollar-sign" href="/guides/findingmostaffordablegpus">
  Search for the most affordable GPUs available right now in Shadeform's cloud provider network.
</Card>
<Card title="Model Serving on GPUs" icon="server" href="/guides/modelserving">
  Serve open source models using vLLM on Shadeform GPUs.
</Card>